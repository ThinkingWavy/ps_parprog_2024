# Exercise 1


## Tasks

1) Open the `mandelbrot.c` file and implement the sequential `calc_mandelbrot` function with the help of the provided pseudocode.

Elapsed wall time: 17.67sec (/bin/time)

2) Check out the generated image `mandelbrot.png` to see if you implemented the algorithm correctly. 

 ![mandelbrot_png](./mandelbrot/results/mandelbrot.png)


3) Benchmark your program on the LCC3 cluster, document your results and add them to the comparison spreadsheet linked on Discord. How would you improve program performance?

The cache misses could be analized. Even more, you could use knowledge of the mandelbrot set and exclude the edges and the center where plain black or white parts are found to improve the performance by skipping calculations.

4) Can you think of a way to parallelize this algorithm?

It is possible to divide the pixels into chunks and run them parallel on different cores to achieve faster image generation.


# Exercise 2

- Hadamard 1:
$$
m(n) = 2 * n^2
$$
Only read misses exist, therefore only two matrices. Every read is a cache miss. 

- Hadamard 2
$$
m(n) = {n*4 \over s}*2
$$


## Valgrind 
Instruction valgrind --tool=cachegrind ./outputfile

```[bash]
first code snippet:
==2826892== Cachegrind, a cache and branch-prediction profiler
==2826892== Copyright (C) 2002-2017, and GNU GPL'd, by Nicholas Nethercote et al.
==2826892== Using Valgrind-3.19.0 and LibVEX; rerun with -h for copyright info
==2826892== Command: ./hadamard1
==2826892== 
--2826892-- warning: L3 cache found, using its data for the LL simulation.
--2826892-- warning: specified LL cache: line_size 64  assoc 16  total_size 12,582,912
--2826892-- warning: simulated LL cache: line_size 64  assoc 24  total_size 12,582,912
==2826892== 
==2826892== I   refs:      6,567,753
==2826892== I1  misses:        1,019
==2826892== LLi misses:          986
==2826892== I1  miss rate:      0.02%
==2826892== LLi miss rate:      0.02%
==2826892== 
==2826892== D   refs:      3,408,225  (2,932,594 rd   + 475,631 wr) -> number of "first level" data cache accesses (memory read) first level closer to cpu (smaller but faster)
==2826892== D1  misses:      100,627  (   34,468 rd   +  66,159 wr)
==2826892== LLd misses:       50,988  (    1,348 rd   +  49,640 wr)
==2826892== D1  miss rate:       3.0% (      1.2%     +    13.9%  ) -> first level data cache miss rate
==2826892== LLd miss rate:       1.5% (      0.0%     +    10.4%  )
==2826892== 
==2826892== LL refs:         101,646  (   35,487 rd   +  66,159 wr) -> number of last level cache accesses (memory write)
==2826892== LL misses:        51,974  (    2,334 rd   +  49,640 wr)
==2826892== LL miss rate:        0.5% (      0.0%     +    10.4%  ) -> last level cache miss rate

second code snippet:
==19600== I   refs:      1,692,488
==19600== I1  misses:          687
==19600== LLi misses:          682
==19600== I1  miss rate:      0.04%
==19600== LLi miss rate:      0.04%
==19600== 
==19600== D   refs:        875,820  (747,744 rd   + 128,076 wr)
==19600== D1  misses:      210,741  (132,380 rd   +  78,361 wr)
==19600== LLd misses:       13,767  (  1,064 rd   +  12,703 wr)
==19600== D1  miss rate:      24.1% (   17.7%     +    61.2%  )
==19600== LLd miss rate:       1.6% (    0.1%     +     9.9%  )
==19600== 
==19600== LL refs:         211,428  (133,067 rd   +  78,361 wr)
==19600== LL misses:        14,449  (  1,746 rd   +  12,703 wr)
==19600== LL miss rate:        0.6% (    0.1%     +     9.9%  )
```
### Interpretation

von Stackoverflow (https://stackoverflow.com/questions/20172216/how-do-you-interpret-cachegrind-output-for-caching-misses)
The first part of cachegrind's output reports information about L1 instructions cache. 
In all your examples, the number of L1 instruction cache misses is insignificant, the miss rate is always 0%. 
It means that all your programs fit in your L1 instruction cache.

The second part of the output reports information about L1 and LL (last level cache, L3 in your case) data caches. 
Using the D1 miss rate: information you should see which version of your matrix multiplication algorithm is "the most cache efficient"

The final part of cachegrind output sums up information about LL (last level cache, L3 in your case) for both instructions and data. 
It thus gives the number of memory accesses and the percentage of memory requests served by the cache.


My Interpretation: 
The first code snippet of the Hadamard Products has relatively seen significantly less cache misses. 
Especially the D1 miss rate, that is mentioned in stack overflow as the one where you can see which one is "the most cache efficient"
is a lot smaller in the first code



## perf 

```
perf

 Performance counter stats for './hadamard1':

               376      LLC-load-misses:u                                           
                 1      LLC-store-misses:u                                          

       0.003793989 seconds time elapsed

       0.001216000 seconds user
       0.002433000 seconds sys

 Performance counter stats for './hadamard2':

               392      LLC-load-misses:u                                           
                 2      LLC-store-misses:u                                          

       0.006669147 seconds time elapsed

       0.005432000 seconds user
       0.001076000 seconds sys

```